from ..utilities import is_valid_cptv10

import datetime as dt
from io import StringIO
import numpy as np
import pandas as pd
from pathlib import Path
import re
import xarray as xr


def cpt_headers(header):
    m = re.compile("(?P<tag>cpt:.*?|cf:.*?)=(?P<value>.*?,|.*$)")
    matches = m.findall(header)
    return len(matches), {i.split(":")[1]: j.replace(",", "") for i, j in matches}


def open_cptdataset(filename):
    assert Path(filename).absolute().is_file(), "Cannot find {}".format(
        Path(filename).absolute()
    )
    with open(str(Path(filename).absolute()), "r") as f:
        content1 = f.read()
    content = [line.strip() for line in content1.split("\n") if "xmlns" not in line]
    xmlnns_lines = [line.strip() for line in content1.split("\n") if "xmlns" in line]
    assert "xmlns:cpt=http://iri.columbia.edu/CPT/v10/" in " ".join(
        xmlnns_lines
    ), "CPT XML Namespace: {} Not detected".format(
        "xmlns:cpt=http://iri.columbia.edu/CPT/v10/"
    )
    headers = [
        (linenum, *cpt_headers(line))
        if "=" in line and "ncats" not in line and "nfields" not in line
        else (linenum, line)
        for linenum, line in enumerate(content)
        if "cpt:" in line
    ]
    attrs, data_vars = {}, {}
    for i, header in enumerate(headers):
        if (
            len(header) == 3
        ):  # we are only looking at the CPT headers that preceed a data block
            attrs_at_row = {
                k: header[2][k] for k in header[2].keys() if k not in ["T", "S"]
            }
            attrs.update(attrs_at_row)

            column_labels = np.genfromtxt(
                StringIO(content[header[0] + 1]), delimiter="\t", dtype=str
            )

            column_labels = (
                np.expand_dims(column_labels, 0)
                if len(column_labels.shape) < 1
                else np.squeeze(column_labels)
            )

            # Non-dimension coordinates that vary with column. These are typically present
            # with station data, where column = station.
            linenum = header[0] + 2
            non_dim_coords = {}
            # linenum >= len(content) shouldn't be possible, but it happens at the end of a subseasonal
            # file when Ingrid crashes because of the fake T grid.
            while linenum < len(content) and content[linenum].startswith('cpt:'):
                vals = content[linenum].split('\t')
                varname = vals[0][4:] # strip 'cpt:'
                vals = np.array(vals[1:])
                # If elev is all NaNs, the .strip() above removes all
                # the tab delimiters. We ought to remove the strip(), but that's more
                # work than it's worth just to save a variable with no values in it.
                if len(vals) == 0:
                    pass
                else:
                    try:
                        vals = vals.astype(float)
                    except ValueError:
                        try:
                            vals = np.asarray([read_cpt_date(ii) for ii in vals])
                        except ValueError:
                            pass
                    non_dim_coords[varname] = (attrs["col"], vals)
                linenum += 1
            
            block = "\n".join(
                content[linenum : linenum + int(attrs["nrow"])]
            )
            if block == "":
                # ignore final header without a block, generated by ingrid just before
                # it crashes because the fake T grid doesn't match the data.
                break
            array = np.genfromtxt(
                StringIO(block),
                delimiter="\t",
                dtype=str,
            )

            if len(array.shape) < 2:
                array = array.reshape(1, -1)

            # Separate row labels from data var values
            row_labels = np.squeeze(array[:, 0])
            row_labels = np.expand_dims(row_labels, 0) if len(row_labels.shape) < 1 else np.squeeze(row_labels)

            # Keep station IDs as strings even if they look like numbers.
            # Avoids unintended floating point rounding.
            if attrs['row'] != 'station':
                try:
                    row_labels = row_labels.astype(float)
                except ValueError:
                    try:
                        row_labels = np.asarray([read_cpt_date(ii) for ii in row_labels])
                    except ValueError:
                        pass
            array = array[:, 1:]

            # In files generated by CPT, for lat/lon data there's no column label
            # on the first column (the latitudes column), but for station data the
            # first column has the label "Station".
            if len(column_labels) > array.shape[1]:
                assert column_labels[0] == 'Station'
                assert column_labels[1] == 'Latitude'
                assert column_labels[2] == 'Longitude'
                column_labels = column_labels[3:]
                lat_vals = np.squeeze(array[:, 0])
                lon_vals = np.squeeze(array[:, 1])
                non_dim_coords['Y'] = ('station', lat_vals)
                non_dim_coords['X'] = ('station', lon_vals)
                array = array[:, 2:]

            data = array.astype(float)

            for k, (dim, vals) in non_dim_coords.items():
                try:
                    non_dim_coords[k] = (dim, vals.astype(float))
                except ValueError:
                    try:
                        non_dim_coords[k] = (dim, np.asarray([read_cpt_date(ii) for ii in vals]))
                    # ValueError as above, or TypeError when columns isn't iterable
                    except Exception:
                        pass

            # Keep station IDs as strings even if they look like numbers.
            # Avoids unintended floating point rounding.
            if attrs['col'] != 'station':
                try:
                    column_labels = column_labels.astype(float)
                except ValueError:
                    try:
                        column_labels = np.asarray([read_cpt_date(ii) for ii in column_labels])
                    # ValueError as above, or TypeError when columns isn't iterable
                    except Exception:
                        pass

            # The first CPT header always has a 'field' field
            # indicating the variable stored. It is assumed to be the
            # same thereafter if not explicitly changed
            field = (
                header[2]["field"] if "field" in header[2].keys() else attrs["field"]
            )

            if field not in data_vars.keys():
                # now identify dimensions: 'T', 'Mode', 'C' - same
                # deal , the same thereafter unless changed.
                rowdim = header[2]["row"] if "row" in header[2].keys() else attrs["row"]
                coldim = header[2]["col"] if "col" in header[2].keys() else attrs["col"]
                somedims = [
                    "T"
                    if "T" in header[2].keys() and "T" not in [rowdim, coldim]
                    else None,
                    "Mode"
                    if "Mode" in header[2].keys() and "Mode" not in [rowdim, coldim]
                    else None,
                    "C"
                    if "C" in header[2].keys() and "C" not in [rowdim, coldim]
                    else None,
                    "M"
                    if "M" in header[2].keys() and "M" not in [rowdim, coldim]
                    else None,
                ]
                somedims = [
                    jj for jj in somedims if jj is not None
                ]  # keep only dims present
                alldims = [rowdim, coldim]
                somedims.extend(alldims)
                alldims = somedims
                coords = {}
                for jj in alldims:
                    if jj not in [rowdim, coldim]:
                        if jj == "T":
                            date_coord = read_cpt_date(header[2][jj])
                            if len(date_coord) == 1:
                                coords[jj] = [date_coord[0]]
                            else:
                                coords["T"] = [date_coord[1]]
                                coords["Ti"] = [date_coord[0]]
                                coords["Tf"] = [date_coord[2]]
                        else:
                            coords[jj] = [header[2][jj]]
                temp = {rowdim: row_labels, coldim: column_labels}
                if "T" in [rowdim, coldim]:
                    date_coords = temp["T"]
                    if len(date_coords[0]) == 1:
                        temp["T"] = [date_coords[ii][0] for ii in range(len(date_coords))]
                    else:
                        temp["T"] = [date_coords[ii][1] for ii in range(len(date_coords))]
                        temp["Ti"] = [date_coords[ii][0] for ii in range(len(date_coords))]
                        temp["Tf"] = [date_coords[ii][2] for ii in range(len(date_coords))]
                coords.update(temp)
                if "S" in header[2].keys():  # S is always a length-1 situation
                    coords.update({"S": [read_cpt_date(header[2]["S"])[0]]})
                ndims = len(alldims)
                if (
                    "C" in alldims and ndims == 4
                ):  # to accomodate 4D data, we sort C to the first
                    # dimension, do all the C's separately, then shove
                    # them together in the end.
                    alldims.pop(alldims.index("C"))
                    alldims.insert(0, "C")
                if (
                    "M" in alldims and ndims == 4
                ):  # to accomodate 4D data, we sort C to the first
                    # dimension, do all the C's separately, then shove
                    # them together in the end.
                    alldims.pop(alldims.index("M"))
                    alldims.insert(0, "M")
                data_vars[field] = {
                    "dims": alldims,
                    "coords": coords,
                    "data": data
                    if ndims == 2
                    else np.expand_dims(data, 0)
                    if ndims == 3
                    else [np.expand_dims(data, 0)]
                    if ndims == 4
                    else None,
                    "attrs": attrs,
                }
            # print('found {}-dimensional variable {}'.format(len(alldims), field))
            else:
                # detect new coordinates in T, C, or Mode:
                for dim in data_vars[field]["coords"].keys():
                    if dim in header[2].keys():
                        if dim == "T":
                            date_coord = read_cpt_date(header[2][dim])
                            if len(date_coord) == 1:
                                if date_coord[0] not in data_vars[field]["coords"][dim]:
                                    data_vars[field]["coords"][dim].append(
                                        date_coord[0]
                                    )
                            else:
                                if date_coord[1] not in data_vars[field]["coords"][dim]:
                                    data_vars[field]["coords"]["T"].append(
                                        date_coord[1]
                                    )
                                    data_vars[field]["coords"]["Ti"].append(
                                        date_coord[0]
                                    )
                                    data_vars[field]["coords"]["Tf"].append(
                                        date_coord[2]
                                    )
                        elif dim == "S":
                            date_coord = read_cpt_date(header[2][dim])[0]
                            if date_coord not in data_vars[field]["coords"][dim]:
                                data_vars[field]["coords"][dim].append(date_coord)
                        else:
                            if header[2][dim] not in data_vars[field]["coords"][dim]:
                                data_vars[field]["coords"][dim].append(header[2][dim])
                if ndims == 3:
                    data_vars[field]["data"] = np.concatenate(
                        (data_vars[field]["data"], np.expand_dims(data, axis=0)), axis=0
                    )
                elif ndims == 4:
                    assert "C" in header[2].keys() or "M" in header[2].keys(), (
                        "Only accomodating 4D data with a C (or M) dimension as the"
                        " highest dimension right now - its coord must change in every"
                        " header"
                    )
                    if "C" in header[2].keys():
                        if (
                            len(data_vars[field]["data"])
                            <= int(float(header[2]["C"])) - 1
                        ):
                            data_vars[field]["data"].append(
                                np.expand_dims(data, axis=0)
                            )
                        else:
                            data_vars[field]["data"][
                                int(float(header[2]["C"])) - 1
                            ] = np.concatenate(
                                (
                                    data_vars[field]["data"][
                                        int(float(header[2]["C"])) - 1
                                    ],
                                    np.expand_dims(data, axis=0),
                                ),
                                axis=0,
                            )
                    if "M" in header[2].keys():
                        if (
                            len(data_vars[field]["data"])
                            <= int(float(header[2]["M"])) - 1
                        ):
                            data_vars[field]["data"].append(
                                np.expand_dims(data, axis=0)
                            )
                        else:
                            data_vars[field]["data"][
                                int(float(header[2]["M"])) - 1
                            ] = np.concatenate(
                                (
                                    data_vars[field]["data"][
                                        int(float(header[2]["M"])) - 1
                                    ],
                                    np.expand_dims(data, axis=0),
                                ),
                                axis=0,
                            )

                data_vars[field]["attrs"].update(attrs)
    # print(data_vars['attributes']['coords'])

    for field in data_vars.keys():
        if len(data_vars[field]["dims"]) == 4:
            data_vars[field]["data"] = np.concatenate(
                [
                    np.expand_dims(data_vars[field]["data"][k], axis=0)
                    for k in range(len(data_vars[field]["data"]))
                ],
                axis=0,
            )
    for f in data_vars.keys():
        data_vars[f]["coords"] = {
            m: ("T" if m in ["S", "Ti", "Tf"] else m, data_vars[f]["coords"][m])
            for m in data_vars[f]["coords"].keys()
        }
        data_vars[f]["coords"].update({
            name: (dim, values)
            for name, (dim, values) in non_dim_coords.items()
        })
    dataarrays = {
        f.replace(" ", "_"): xr.DataArray(
            data_vars[f]["data"],
            dims=data_vars[f]["dims"],
            coords=data_vars[f]["coords"],
            attrs=data_vars[f]["attrs"],
        )
        for f in data_vars.keys()
    }
    for k in dataarrays.keys():
        is_valid_cptv10(dataarrays[k], assert_units=False, assertmissing=False)
        if "missing" in dataarrays[k].attrs.keys():
            dataarrays[k] = dataarrays[k].where(
                dataarrays[k] != float(dataarrays[k].attrs["missing"]), other=np.nan
            )
    return xr.Dataset(dataarrays)


def open_cptdataarray(path):
    'Like cptio.open_cptdataset but returns a DataArray instead of a Dataset'
    ds = open_cptdataset(path)
    das = list(ds.data_vars.values())
    assert len(das) == 1
    return das[0]


def datetime_timestamp(date):
    if "T" in date:
        ymd, hms = date.split("T")
    else:
        ymd = date

    fields = [int(i) for i in ymd.split("-")]
    while len(fields) < 3:
        fields.append(1)
    return dt.datetime(*fields)


def datetime_timestamp_end(date):
    if "T" in date:
        ymd, hms = date.split("T")
    else:
        ymd = date
    fields = [int(i) for i in ymd.split("-")]
    y = fields[0]
    m = fields[1]
    if len(fields) == 3:
        d = fields[2]
    elif len(fields) == 2:
        if m == 12:
            d = 31
        else:
            # Find the first day of the following month, then back up
            # one day.
            d = (dt.datetime(y, m + 1, 1) - dt.timedelta(days=1)).day
    else:
        assert False, f"Can't parse date {ymd}"
    return dt.datetime(y, m, d)


def read_cpt_date(date_original):
    if "/" in date_original:
        date1, date2 = date_original.split("/")
        date1, date2 = date1.split("T")[0], date2.split("T")[0]
        date1, date2 = date1.split(" ")[0], date2.split(" ")[0]
        if len(date1.split("-")) == len(date2.split("-")):
            ret1, ret2 = datetime_timestamp(date1), datetime_timestamp_end(date2)
        else:
            assert len(date1.split("-")) > len(
                date2.split("-")
            ), "date1 must have more elements than date2"
            ymd = date1.split("-")
            ymd2 = date2.split("-")
            ymd2 = ymd[: len(ymd) - len(ymd2)] + ymd2
            ret1, ret2 = datetime_timestamp(date1), datetime_timestamp_end(
                "-".join(ymd2) if len(ymd2) > 1 else ymd2[0]
            )
        return [ret1, ret1 + (ret2 - ret1) / 2, ret2]
    else:
        return [datetime_timestamp(date_original)]


convert_np64_datetime = pd.Timestamp


def guess_cptv10_coords(da, row=None, col=None, T=None, C=None):
    ret = {"row": row, "col": col, "T": T, "C": C}
    guesses = {
        "row": ["Y", "T", "station", "Mode"],
        "col": ["X", "index", "Mode", "station"],
        "T": ["T", "Mode"],
        "C": ["C", "M"],
    }
    found = []
    for dim in ["row", "col", "T", "C"]:
        for guess in guesses[dim]:
            if (
                    guess in da.dims and 
                    (ret[dim] is None or ret[dim] == guess) and
                    guess not in found
            ):
                ret[dim] = guess
                found.append(guess)
    guesses = [ret[i] for i in ret.keys() if ret[i] is not None]
    found_dims = []
    while len(guesses) > 0:
        guess = guesses.pop(0)
        assert (
            guess not in found_dims
        ), "repeated dimension in guesses (None excluded)- {}".format(ret)
        found_dims.append(guess)
    assert len(found_dims) == len(
        da.dims
    ), "Unable to guess names of all dims on da accurately - guessed {} vs {}".format(
        ret, da.dims
    )
    for dim in found_dims:
        assert (
            dim in da.dims
        ), "guessed a dimension not present on da - {} vs {}".format(ret, da.dims)
    return ret["row"], ret["col"], ret["T"], ret["C"]


def to_cptv10(
    da,
    opfile="cptv10.tsv",
    row=None,
    col=None,
    T=None,
    C=None,
    assertmissing=True,
    assert_units=True,
):
    row, col, T, C = guess_cptv10_coords(da, row, col, T, C)
    is_valid_cptv10(da, assert_units=assert_units, assertmissing=assertmissing)
    assert type(da) == xr.DataArray, "Can only write Xr.DataArray to CPTv10"
    extra_dims = [i for i in [T, C] if i is not None]
    assert (
        row is not None and col is not None
    ), "CPTv10 datasets must have at least two dimensions"
    dims = extra_dims + [row, col]
    for dim in dims:
        assert dim in da.dims, "missing dim from data array - {}".format(dim)
        assert (
            dim in da.coords.keys()
        ), "missing coordinate from data array - {}".format(dim)
        assert (
            len(da.coords[dim].values) == da.shape[list(da.dims).index(dim)]
        ), "data array coord {} not the same size as the dimension".format(dim)
    assert len(dims) == len(
        da.dims
    ), f"Data Array has dims {da.dims}, but you only passed {dims}"
    missingblurb = (
        ", cpt:missing={:#g}".format(float(da.attrs["missing"]))
        if assertmissing
        else ""
    )
    unitsblurb = f", cpt:units={da.attrs['units']}" if assert_units else ""
    with open(opfile, "w") as f:
        f.write("xmlns:cpt=http://iri.columbia.edu/CPT/v10/" + "\n")
        f.write("cpt:nfields=1" + "\n")
        if C is not None:
            f.write(f"cpt:ncats={da.shape[list(da.dims).index(C)]}\n")
        if len(extra_dims) == 2:
            da = da.transpose(T, C, row, col)
            for i in range(da.shape[list(da.dims).index(T)]):
                for j in range(da.shape[list(da.dims).index(C)]):
                    if 'Ti' in da.coords:
                        dates = format_date_range(
                            da.coords['Ti'].values[i],
                            da.coords['Tf'].values[i]
                        )
                    else:
                        dates = format_date(da.coords[T].values[i])
                    if 'S' in da.coords:
                        s = convert_np64_datetime(da.coords['S'].values[i])
                        s_part = f", cpt:S={s.strftime('%Y-%m-%dT%H:%M')}"
                    else:
                        s_part = ""
                    if C == 'C':
                        prob_part = ", cpt:clim_prob=0.33333"
                    else:
                        prob_part = ""
                    header = (
                        f"cpt:field={da.name}"
                        f", cpt:{T}={dates}"
                        f"{s_part}"
                        f", cpt:{C}={da.coords[C].values[j]}"
                        f"{prob_part}"
                        f", cpt:nrow={da.shape[list(da.dims).index(row)]}"
                        f", cpt:ncol={da.shape[list(da.dims).index(col)]}"
                        f", cpt:row={row}, cpt:col={col}"
                        f"{unitsblurb}{missingblurb}\n"
                    )
                    if assertmissing:
                        temp = (
                            da.isel({T: i, C: j})
                            .fillna(float(da.attrs["missing"]))
                            .values
                        )
                    else:
                        temp = da.isel({T: i, C: j}).values

                    f.write(header)
                    if row == "T" or col == "T":
                        tcoords_temp = [
                            format_date_range(ti, tf)
                            for ti, tf in zip(
                                da.coords["Ti"].values,
                                da.coords["Tf"].values
                            )
                        ]
                        tcoords = np.asarray(tcoords_temp, dtype="object")
                    if col != "T":
                        vals = da.coords[col].values
                    else:
                        vals = tcoords
                    f.write(
                        "\t"
                        + "\t".join(format_coord_values(vals))
                        + "\n"
                    )
                    if row != "T":
                        temp = np.hstack([da.coords[row].values.reshape(-1, 1), temp])
                    else:
                        temp = np.hstack(
                            [tcoords.reshape(-1, 1), temp.astype("object")]
                        )
                    if row != "T":
                        np.savetxt(f, temp, fmt="%#g", delimiter="\t")
                    else:
                        np.savetxt(f, temp, fmt="%s", delimiter="\t")
        elif len(extra_dims) == 1 and T is not None:
            da = da.transpose(T, row, col)
            for i in range(da.shape[list(da.dims).index(T)]):
                if 'Ti' in da.coords:
                    dates = format_date_range(
                        da.coords['Ti'].values[i],
                        da.coords['Tf'].values[i]
                    )
                else:
                    dates = format_date(da.coords[T].values[i])
                if 'S' in da.coords:
                    s = convert_np64_datetime(da.coords['S'].values[i])
                    s_part = f", cpt:S={s.strftime('%Y-%m-%dT%H:%M')}"
                else:
                    s_part = ""
                header = (
                    f"cpt:field={da.name}"
                    f", cpt:{T}={dates}"
                    f"{s_part}"
                    f", cpt:nrow={da.shape[list(da.dims).index(row)]}"
                    f", cpt:ncol={da.shape[list(da.dims).index(col)]}"
                    f", cpt:row={row}, cpt:col={col}"
                    f"{unitsblurb}{missingblurb}\n"
                )
                if assertmissing:
                    temp = da.isel({T: i}).fillna(float(da.attrs["missing"])).values
                else:
                    temp = da.isel({T: i}).values
                f.write(header)
                if row == "T" or col == "T":
                    tcoords_temp = [
                        format_date_range(ti, tf)
                        for ti, tf in zip(
                            da.coords["Ti"].values,
                            da.coords["Tf"].values
                        )
                    ]
                    tcoords = np.asarray(tcoords_temp, dtype="object")
                if col != "T":
                    vals = da.coords[col].values
                else:
                    vals = tcoords
                f.write(
                    "\t"
                    + "\t".join(format_coord_values(vals))
                    + "\n"
                )
                if row != "T":
                    temp = np.hstack([da.coords[row].values.reshape(-1, 1), temp])
                else:
                    temp = np.hstack([tcoords.reshape(-1, 1), temp.astype("object")])
                if row != "T":
                    np.savetxt(f, temp, fmt="%#g", delimiter="\t")
                else:
                    np.savetxt(f, temp, fmt="%s", delimiter="\t")

        elif len(extra_dims) == 1 and C is not None:
            da = da.transpose(C, row, col)
            for j in range(da.shape[list(da.dims).index(C)]):
                header = (
                    f"cpt:field={da.name},"
                    f" cpt:{C}={da.coords[C].values[j]}{', cpt:clim_prob=0.33333' if C=='C' else ''},"
                    f" cpt:nrow={da.shape[list(da.dims).index(row)]},"
                    f" cpt:ncol={da.shape[list(da.dims).index(col)]}, cpt:row={row},"
                    f" cpt:col={col}{unitsblurb}{missingblurb}\n"
                )
                if assertmissing:
                    temp = da.isel({C: j}).fillna(float(da.attrs["missing"])).values
                else:
                    temp = da.isel({C: j}).values
                temp = np.vectorize(str)(temp)
                f.write(header)
                if row == "T" or col == "T":
                    if 'Ti' in da.coords:
                        tcoords_temp = [
                            format_date_range(ti, tf)
                            for ti, tf in zip(
                                da.coords["Ti"].values,
                                da.coords["Tf"].values
                            )
                        ]
                    else:
                        tcoords_temp = [
                            format_date(ti)
                            for ti in da.coords["T"].values
                        ]
                    tcoords = np.asarray(tcoords_temp, dtype="object")
                if col != "T":
                    vals = da.coords[col].values
                else:
                    vals = tcoords
                f.write(
                    "\t"
                    + "\t".join(format_coord_values(vals))
                    + "\n"
                )

                # column non-dimension coordinate values
                non_dim_coords = [c for c in da.coords if c not in da.dims]
                for c in non_dim_coords:
                    coord = da.coords[c]
                    assert len(coord.dims) == 1
                    if coord.dims == (col,):
                        f.write(f"cpt:{c}\t")
                        f.write("\t".join(format_coord_values(da.coords[c].values)))
                        f.write("\n")

                if row != "T":
                    temp = np.hstack([da.coords[row].values.reshape(-1, 1), temp])
                else:
                    temp = np.hstack([tcoords.reshape(-1, 1), temp.astype("object")])
                if row != "T":
                    np.savetxt(f, temp, fmt="%#g", delimiter="\t")
                else:
                    np.savetxt(f, temp, fmt="%s", delimiter="\t")
        else:
            # preprocessing
            da = da.transpose(row, col)
            if row == "T" or col == "T":
                if 'Ti' in da.coords:
                    tcoords_temp = [
                        format_date_range(ti, tf)
                        for ti, tf in zip(
                            da.coords["Ti"].values,
                            da.coords["Tf"].values
                        )
                    ]
                else:
                    tcoords_temp = [
                        format_date(ti)
                        for ti in da.coords["T"].values
                    ]
                tcoords = np.asarray(tcoords_temp, dtype="object")


            # header
            header = (
                f"cpt:field={da.name}, cpt:nrow={da.shape[list(da.dims).index(row)]},"
                f" cpt:ncol={da.shape[list(da.dims).index(col)]}, cpt:row={row},"
                f" cpt:col={col}{unitsblurb}{missingblurb}\n"
            )
            f.write(header)

            # column dimension coordinate values
            if col != "T":
                vals = da.coords[col].values
            else:
                vals = tcoords
            f.write("\t" + "\t".join(format_coord_values(vals)) + "\n")

            # column non-dimension coordinate values
            non_dim_coords = [c for c in da.coords if c not in da.dims]
            # For station data, X and Y must come first
            if 'X' in non_dim_coords:
                assert 'Y' in non_dim_coords
                non_dim_coords = ['X', 'Y'] + list(set(non_dim_coords) - set(['X', 'Y']))
            for c in non_dim_coords:
                coord = da.coords[c]
                assert len(coord.dims) == 1
                if coord.dims == (col,):
                    f.write(f"cpt:{c}\t")
                    f.write("\t".join(format_coord_values(da.coords[c].values)))
                    f.write("\n")

            if assertmissing:
                temp = da.fillna(float(da.attrs["missing"])).values
            else:
                temp = da.values
            temp = np.vectorize(str)(temp)
            
            # row dimension coordinate values
            if row != "T":
                row_labels = np.array([f"{x:#g}" for x in da[row].values]).reshape(-1, 1)
            else:
                row_labels = np.array([str(x) for x in tcoords]).reshape(-1, 1)

            # concatenate coord and data var representations
            temp = np.hstack([row_labels, temp])

            np.savetxt(f, temp, fmt="%s", delimiter="\t")
    return opfile


def format_float_value(f):
    if np.isnan(f):
        return ''
    return f"{f:#g}"


def format_coord_values(array):
    if np.issubdtype(array.dtype, np.floating):
        return [format_float_value(x) for x in array]
    return [f"{x}" for x in array]


def format_date(t):
    return t


def format_date_range(ti, tf):
    ti = convert_np64_datetime(ti)
    tf = convert_np64_datetime(tf)
    # If it looks like a season (sequence of full months), use monthly
    # notation instead of daily. While it's usually ok to represent a
    # season using daily notation, it's not ok if the season ends in
    # February, because when using the daily notation, CPT rejects
    # seasons whose length is different in leap years.
    if is_season(ti, tf):
        result = f"{ti.year}-{ti.month}/{tf.year}-{tf.month}"
    else:
        result = f"{ti.year}-{ti.month}-{ti.day}/{tf.year}-{tf.month}-{tf.day}"
    return result


def is_season(ti, tf):
    '''True if ti is the first day of a month and tf is the last day of a month.'''
    return ti.day == 1 and (tf + dt.timedelta(days=1)).day == 1
